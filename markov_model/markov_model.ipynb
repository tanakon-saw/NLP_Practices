{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "robert_frost_file_path = \"../data/robert_frost.txt\" #robert_frost_small robert_frost\n",
    "edgar_allan_poe_file_path = \"../data/edgar_allan_poe.txt\" #edgar_allan_poe_small edgar_allan_poe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_word(lst):\n",
    "    return [x.lower().translate(str.maketrans('', '', string.punctuation)) for x in lst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_to_tokenize(file_path):\n",
    "    '''\n",
    "    This function purpose is to read file and convert to list of tokenize\n",
    "    '''\n",
    "    tokenize_list = []\n",
    "    f = open(file_path, \"r\")\n",
    "    for x in f:\n",
    "        tokenize_list.append(x.split())\n",
    "        \n",
    "    # remove empty array\n",
    "    tokenize_list = [ x for x in tokenize_list if len(x) != 0]\n",
    "    \n",
    "    #preprocessing\n",
    "    tmp = []\n",
    "    for x in tokenize_list:\n",
    "        tmp.append(preprocessing_word(x))\n",
    "        \n",
    "    tokenize_list = tmp\n",
    "        \n",
    "    return tokenize_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1436, 722)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read file and convert to tokenize by function file_to_tokenize\n",
    "robert_frost_tokenize_list = file_to_tokenize(robert_frost_file_path)\n",
    "edgar_allan_poe_tokenize_list = file_to_tokenize(edgar_allan_poe_file_path)\n",
    "len(robert_frost_tokenize_list),len(edgar_allan_poe_tokenize_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['two', 'roads', 'diverged', 'in', 'a', 'yellow', 'wood'],\n",
       " ['and', 'sorry', 'i', 'could', 'not', 'travel', 'both'],\n",
       " ['and', 'be', 'one', 'traveler', 'long', 'i', 'stood'],\n",
       " ['and', 'looked', 'down', 'one', 'as', 'far', 'as', 'i', 'could'],\n",
       " ['to', 'where', 'it', 'bent', 'in', 'the', 'undergrowth']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "robert_frost_tokenize_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['lo', 'death', 'hath', 'reard', 'himself', 'a', 'throne'],\n",
       " ['in', 'a', 'strange', 'city', 'all', 'alone'],\n",
       " ['far', 'down', 'within', 'the', 'dim', 'west'],\n",
       " ['where',\n",
       "  'the',\n",
       "  'good',\n",
       "  'and',\n",
       "  'the',\n",
       "  'bad',\n",
       "  'and',\n",
       "  'the',\n",
       "  'worst',\n",
       "  'and',\n",
       "  'the',\n",
       "  'best'],\n",
       " ['have', 'gone', 'to', 'their', 'eternal', 'rest']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edgar_allan_poe_tokenize_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1436, 722)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "robert_frost_label_list = list(np.zeros(len(robert_frost_tokenize_list),dtype=int))\n",
    "edgar_allan_poe_label_list = list(np.ones(len(edgar_allan_poe_tokenize_list),dtype=int))\n",
    "\n",
    "len(robert_frost_label_list),len(edgar_allan_poe_label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2158, 2158)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data_x = robert_frost_tokenize_list+edgar_allan_poe_tokenize_list\n",
    "all_data_y= robert_frost_label_list+edgar_allan_poe_label_list\n",
    "\n",
    "len(all_data_x),len(all_data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1726, 1726, 432, 432)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(all_data_x, all_data_y, test_size=0.2, random_state=42)\n",
    "len(X_train),len(y_train),len(X_test),len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['its', 'hands', 'of', 'gold'],\n",
       " ['i', 'may', 'be', 'mad'],\n",
       " ['and', 'the', 'fur', 'trade'],\n",
       " ['winds', 'blow', 'the', 'open', 'grassy', 'places', 'bleak'],\n",
       " ['at', 'having', 'eased', 'her', 'heart', 'of', 'one', 'more', 'copy']]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['there', 'is', 'a', 'house', 'that', 'is', 'no', 'more', 'a', 'house'],\n",
       " ['but',\n",
       "  'you',\n",
       "  'have',\n",
       "  'said',\n",
       "  'it',\n",
       "  'and',\n",
       "  'were',\n",
       "  'off',\n",
       "  'to',\n",
       "  'find',\n",
       "  'it'],\n",
       " ['and', 'the', 'birds', 'on', 'her', 'outer', 'windowsill'],\n",
       " ['by', 'tying', 'together'],\n",
       " ['with', 'furs', 'to', 'sell']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapping_unique_index(lst):\n",
    "    unique_word_index_dict = {\n",
    "         'unk' : 0\n",
    "    }\n",
    "    word_index = 1\n",
    "    for data in lst:\n",
    "        tmp = np.asarray(data)\n",
    "        unique_tmp = np.unique(tmp)\n",
    "        for word in unique_tmp:\n",
    "            if not word in unique_word_index_dict:\n",
    "                unique_word_index_dict[word] = word_index\n",
    "                word_index += 1\n",
    "    return unique_word_index_dict,word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_unique_word_index_dict,X_train_word_index = mapping_unique_index(X_train)\n",
    "X_test_unique_word_index_dict,X_test_word_index = mapping_unique_index(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'unk': 0, 'gold': 1, 'hands': 2, 'its': 3, 'of': 4}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(list(X_train_unique_word_index_dict.items())[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding a key that found in test set but not in trainset\n",
    "# in case, want to visualize\n",
    "X_train_keys_set= set(list(X_train_unique_word_index_dict.keys()))\n",
    "X_test_keys_set= set(list(X_test_unique_word_index_dict.keys()))\n",
    "\n",
    "not_found_keys = X_test_keys_set - X_train_keys_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'unk', 1: 'gold', 2: 'hands', 3: 'its', 4: 'of'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating dictionary for mapping from index to word \n",
    "X_train_unique_index_word_dict = dict((v,k) for k,v in X_train_unique_word_index_dict.items())\n",
    "dict(list(X_train_unique_index_word_dict.items())[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def covert_word_str_to_int(lst,mapping_dict):\n",
    "    word_int_list = []\n",
    "    \n",
    "    for sentence in lst:\n",
    "        tmp = [mapping_dict[word] if word in mapping_dict else 0 for word in sentence]\n",
    "        word_int_list.append(tmp)\n",
    "        \n",
    "    return word_int_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1726, 432)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert from list of string of word to list of index of word\n",
    "X_train_int = covert_word_str_to_int(X_train,X_train_unique_word_index_dict)\n",
    "X_test_int = covert_word_str_to_int(X_test,X_train_unique_word_index_dict)\n",
    "\n",
    "X_train_int = np.asarray(X_train_int)\n",
    "X_test_int = np.asarray(X_test_int)\n",
    "\n",
    "len(X_train_int),len(X_test_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list([3, 2, 4, 1]), list([6, 8, 5, 7]), list([9, 11, 10, 12]),\n",
       "       list([18, 14, 11, 16, 15, 17, 13]),\n",
       "       list([19, 22, 21, 24, 23, 4, 26, 25, 20])], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_int[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list([300, 146, 37, 201, 104, 146, 30, 25, 37, 201]),\n",
       "       list([167, 94, 69, 404, 183, 9, 84, 172, 59, 390, 183]),\n",
       "       list([9, 11, 329, 86, 24, 0, 684]), list([246, 0, 416]),\n",
       "       list([311, 0, 59, 562])], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_int[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model seperately for each class  , smoothing by 1\n",
    "state_transition_0  = np.ones((X_train_word_index,X_train_word_index))\n",
    "initial_state_0 = np.ones(X_train_word_index)\n",
    "\n",
    "state_transition_1  = np.ones((X_train_word_index,X_train_word_index))\n",
    "initial_state_1 = np.ones(X_train_word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute counting for state transition and initial state \n",
    "def compute_counting(lst,initial_state,state_transition):\n",
    "    for tokens in lst:\n",
    "        last_index = None\n",
    "        for idx in tokens:\n",
    "            if last_index is None:\n",
    "                initial_state[idx] += 1\n",
    "            else:\n",
    "                state_transition[last_index,idx] +=1\n",
    "            last_index = idx\n",
    "\n",
    "    initial_state /= initial_state.sum()\n",
    "    state_transition /= state_transition.sum(axis=1,keepdims=True)\n",
    "    \n",
    "    \n",
    "    initial_state = np.log(initial_state)\n",
    "    state_transition =np.log( state_transition)\n",
    "    return initial_state,state_transition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-8.23589073, -8.23589073, -8.23589073, -5.40267738, -5.0170149 ]),\n",
       " array([[-7.87435882, -7.87435882, -7.87435882, ..., -7.87435882,\n",
       "         -7.87435882, -7.87435882],\n",
       "        [-7.87511928, -7.87511928, -7.87511928, ..., -7.87511928,\n",
       "         -7.87511928, -7.87511928],\n",
       "        [-7.87511928, -7.87511928, -7.87511928, ..., -7.87511928,\n",
       "         -7.87511928, -7.87511928],\n",
       "        [-7.88870952, -7.88870952, -7.19556234, ..., -7.88870952,\n",
       "         -7.88870952, -7.88870952],\n",
       "        [-7.93272103, -6.83410874, -7.93272103, ..., -7.93272103,\n",
       "         -7.93272103, -7.93272103]]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_state_0,state_transition_0 = compute_counting([x for x,y in zip(X_train_int,y_train) if y ==0],initial_state_0,state_transition_0)\n",
    "initial_state_0[:5],state_transition_0[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-8.07402622, -8.07402622, -8.07402622, -6.97541393, -4.89597239]),\n",
       " array([[-7.87435882, -7.87435882, -7.87435882, ..., -7.87435882,\n",
       "         -7.87435882, -7.87435882],\n",
       "        [-7.87473913, -7.87473913, -7.87473913, ..., -7.87473913,\n",
       "         -7.87473913, -7.87473913],\n",
       "        [-7.87473913, -7.87473913, -7.87473913, ..., -7.87473913,\n",
       "         -7.87473913, -7.87473913],\n",
       "        [-7.8800482 , -7.8800482 , -7.8800482 , ..., -7.8800482 ,\n",
       "         -7.8800482 , -7.8800482 ],\n",
       "        [-7.92876632, -7.92876632, -7.92876632, ..., -7.92876632,\n",
       "         -7.92876632, -7.92876632]]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_state_1,state_transition_1 = compute_counting([x for x,y in zip(X_train_int,y_train) if y ==1],initial_state_1,state_transition_1)\n",
    "initial_state_1[:5],state_transition_1[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6633835457705678, 0.3366164542294322)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#compute prior\n",
    "count_0 = sum(y == 0 for y in y_train)\n",
    "count_1 = sum(y == 1 for y in y_train)\n",
    "total_count = len(y_train)\n",
    "\n",
    "p0 = count_0/total_count\n",
    "p1 = count_1/total_count\n",
    "\n",
    "log_p0 = np.log(p0)\n",
    "log_p1 = np.log(p1)\n",
    "\n",
    "p0,p1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_log_likelihood(tokens,initial_state,state_transition):\n",
    "    log_prob = 0\n",
    "    last_index = None\n",
    "    for idx in tokens:\n",
    "        if last_index is None:\n",
    "            log_prob += initial_state[idx]\n",
    "        else:\n",
    "            log_prob +=state_transition[last_index,idx]\n",
    "        last_index = idx\n",
    "    \n",
    "    return log_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(test_sentences,initial_state_list,state_transition_list,prior_list):\n",
    "    \n",
    "    prob =[]\n",
    "    for sentence in test_sentences:\n",
    "        \n",
    "        prob_each_model = []\n",
    "        model_number = len(initial_state_list)\n",
    "        \n",
    "        for i in range(model_number):\n",
    "            tmp_prob = compute_log_likelihood(sentence,initial_state_list[i],state_transition_list[i]) + prior_list[i]\n",
    "            prob_each_model.append(tmp_prob)\n",
    "       \n",
    "        pred = np.argmax(prob_each_model)\n",
    "        prob.append(pred)\n",
    "        \n",
    "    return np.asarray(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9959443800695249"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_train = predict(X_train_int,[initial_state_0,initial_state_1],[state_transition_0,state_transition_1],[log_p0,log_p1]  )\n",
    "np.mean(predicted_train ==np.asarray(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8402777777777778"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_test = predict(X_test_int,[initial_state_0,initial_state_1],[state_transition_0,state_transition_1],[log_p0,log_p1])\n",
    "np.mean(predicted_test ==np.asarray(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
