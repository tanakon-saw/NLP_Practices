{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "robert_frost_file_path = \"../data/robert_frost.txt\" #robert_frost_small robert_frost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_word(lst):\n",
    "    return [x.lower().translate(str.maketrans('', '', string.punctuation)) for x in lst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_to_tokenize(file_path):\n",
    "    '''\n",
    "    This function purpose is to read file and convert to list of tokenize\n",
    "    '''\n",
    "    tokenize_list = []\n",
    "    f = open(file_path, \"r\")\n",
    "    for x in f:\n",
    "        tokenize_list.append(x.split())\n",
    "        \n",
    "    # remove empty array\n",
    "    tokenize_list = [ x for x in tokenize_list if len(x) != 0]\n",
    "    \n",
    "    #preprocessing\n",
    "    tmp = []\n",
    "    for x in tokenize_list:\n",
    "        tmp.append(preprocessing_word(x))\n",
    "        \n",
    "    tokenize_list = tmp\n",
    "        \n",
    "    return tokenize_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1436"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read file and convert to tokenize by function file_to_tokenize\n",
    "robert_frost_tokenize_list = file_to_tokenize(robert_frost_file_path)\n",
    "len(robert_frost_tokenize_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['two', 'roads', 'diverged', 'in', 'a', 'yellow', 'wood'],\n",
       " ['and', 'sorry', 'i', 'could', 'not', 'travel', 'both'],\n",
       " ['and', 'be', 'one', 'traveler', 'long', 'i', 'stood'],\n",
       " ['and', 'looked', 'down', 'one', 'as', 'far', 'as', 'i', 'could'],\n",
       " ['to', 'where', 'it', 'bent', 'in', 'the', 'undergrowth']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "robert_frost_tokenize_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1436"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "robert_frost_label_list = list(np.zeros(len(robert_frost_tokenize_list),dtype=int))\n",
    "len(robert_frost_label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1436, 1436)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data_x = robert_frost_tokenize_list\n",
    "all_data_y= robert_frost_label_list\n",
    "\n",
    "len(all_data_x),len(all_data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1148, 1148, 288, 288)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(all_data_x, all_data_y, test_size=0.2, random_state=42)\n",
    "len(X_train),len(y_train),len(X_test),len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['anything', 'she', 'may', 'say', 'but', 'let', 'me', 'warn', 'you'],\n",
       " ['among', 'the', 'raspberries', 'and', 'hew', 'and', 'shape', 'it'],\n",
       " ['off', 'from', 'the', 'house', 'as', 'far', 'as', 'we', 'could', 'keep'],\n",
       " ['the', 'cosmic', 'motes'],\n",
       " ['of', 'easy', 'wind', 'and', 'downy', 'flake']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['it',\n",
       "  'was',\n",
       "  'the',\n",
       "  'bones',\n",
       "  'i',\n",
       "  'knew',\n",
       "  'them',\n",
       "  '',\n",
       "  'and',\n",
       "  'good',\n",
       "  'reason'],\n",
       " ['some', 'zealous', 'ones', 'laborious', 'device'],\n",
       " ['dont', 'make', 'me', 'get', 'up', 'im', 'too', 'warm', 'in', 'bed'],\n",
       " ['where', 'is', 'estelle'],\n",
       " ['well', 'then', 'its', 'granny', 'speaking', 'i', 'dunnow']]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapping_unique_index(lst):\n",
    "    unique_word_index_dict = {\n",
    "         'unk' : 0\n",
    "    }\n",
    "    word_index = 1\n",
    "    for data in lst:\n",
    "        tmp = np.asarray(data)\n",
    "        unique_tmp = np.unique(tmp)\n",
    "        for word in unique_tmp:\n",
    "            if not word in unique_word_index_dict:\n",
    "                unique_word_index_dict[word] = word_index\n",
    "                word_index += 1\n",
    "    return unique_word_index_dict,word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_unique_word_index_dict,X_train_word_index = mapping_unique_index(X_train)\n",
    "X_test_unique_word_index_dict,X_test_word_index = mapping_unique_index(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'unk': 0, 'anything': 1, 'but': 2, 'let': 3, 'may': 4}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(list(X_train_unique_word_index_dict.items())[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding a key that found in test set but not in trainset\n",
    "# in case, want to visualize\n",
    "X_train_keys_set= set(list(X_train_unique_word_index_dict.keys()))\n",
    "X_test_keys_set= set(list(X_test_unique_word_index_dict.keys()))\n",
    "\n",
    "not_found_keys = X_test_keys_set - X_train_keys_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'unk', 1: 'anything', 2: 'but', 3: 'let', 4: 'may'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating dictionary for mapping from index to word \n",
    "X_train_unique_index_word_dict = dict((v,k) for k,v in X_train_unique_word_index_dict.items())\n",
    "dict(list(X_train_unique_index_word_dict.items())[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def covert_word_str_to_int(lst,mapping_dict):\n",
    "    word_int_list = []\n",
    "    \n",
    "    for sentence in lst:\n",
    "        tmp = [mapping_dict[word] if word in mapping_dict else 0 for word in sentence]\n",
    "        word_int_list.append(tmp)\n",
    "        \n",
    "    return word_int_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1148, 288)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert from list of string of word to list of index of word\n",
    "X_train_int = covert_word_str_to_int(X_train,X_train_unique_word_index_dict)\n",
    "X_test_int = covert_word_str_to_int(X_test,X_train_unique_word_index_dict)\n",
    "\n",
    "X_train_int = np.asarray(X_train_int)\n",
    "X_test_int = np.asarray(X_test_int)\n",
    "\n",
    "len(X_train_int),len(X_test_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list([1, 7, 4, 6, 2, 3, 5, 8, 9]),\n",
       "       list([10, 16, 14, 11, 12, 11, 15, 13]),\n",
       "       list([23, 20, 16, 21, 17, 19, 17, 24, 18, 22]), list([16, 25, 26]),\n",
       "       list([30, 28, 31, 11, 27, 29])], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_int[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list([13, 37, 16, 335, 73, 866, 200, 224, 11, 388, 1074]),\n",
       "       list([64, 0, 808, 0, 0]),\n",
       "       list([437, 199, 5, 543, 53, 157, 375, 1533, 40, 366]),\n",
       "       list([58, 127, 208]), list([76, 51, 258, 1252, 1158, 73, 0])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_int[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model using dict\n",
    "first_order_state_transition  = None\n",
    "first_order_initial_state = None\n",
    "\n",
    "second_order_state_transition  = None\n",
    "second_order_initial_state = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute counting for state transition and initial state \n",
    "def compute_counting(lst):\n",
    "    first_order_state_transition  = {}\n",
    "    initial_state = {}\n",
    "\n",
    "    second_order_state_transition  = {}\n",
    "    counting_dict = {}\n",
    "    \n",
    "    for tokens in lst:    \n",
    "         \n",
    "        first_index = None\n",
    "        second_index = None\n",
    "        counting_word = 1\n",
    "        for idx in tokens:\n",
    "            if idx not in counting_dict:\n",
    "                counting_dict[idx] = 1\n",
    "            else:\n",
    "                counting_dict[idx] += 1\n",
    "                \n",
    "            if counting_word == 1:\n",
    "                if idx not in initial_state:\n",
    "                    initial_state[idx] = 1\n",
    "                else:\n",
    "                    initial_state[idx] += 1\n",
    "                    \n",
    "\n",
    "            if counting_word == 2:\n",
    "                if first_index not in first_order_state_transition:\n",
    "                    first_order_state_transition[first_index] = {}\n",
    "                if idx not in first_order_state_transition[first_index]:\n",
    "                    first_order_state_transition[first_index][idx] = 1\n",
    "                else:\n",
    "                    first_order_state_transition[first_index][idx] += 1\n",
    "                    \n",
    "                    \n",
    "            if counting_word >= 3:\n",
    "                if first_index not in first_order_state_transition:\n",
    "                    first_order_state_transition[first_index] = {}\n",
    "                if idx not in first_order_state_transition[first_index]:\n",
    "                    first_order_state_transition[first_index][idx] = 1\n",
    "                else:\n",
    "                    first_order_state_transition[first_index][idx] += 1\n",
    "                    \n",
    "                if second_index not in second_order_state_transition:\n",
    "                    second_order_state_transition[second_index] = {}\n",
    "                    \n",
    "                if first_index not in second_order_state_transition[second_index]:\n",
    "                    second_order_state_transition[second_index][first_index] = {}\n",
    "                \n",
    "                if idx not in second_order_state_transition[second_index][first_index]:\n",
    "                    second_order_state_transition[second_index][first_index][idx] = 1\n",
    "                else:\n",
    "                    second_order_state_transition[second_index][first_index][idx] += 1\n",
    "                    \n",
    "\n",
    "#             if counting_word >= 3:\n",
    "#                 if first_index not in first_order_state_transition:\n",
    "#                     first_order_state_transition[first_index] = {}\n",
    "#                 if idx not in first_order_state_transition[first_index]:\n",
    "#                     first_order_state_transition[first_index][idx] = 1\n",
    "#                 else:\n",
    "#                     first_order_state_transition[first_index][idx] += 1\n",
    "                \n",
    "#                 if second_index not in second_order_state_transition:\n",
    "#                     second_order_state_transition[second_index] = {}\n",
    "                    \n",
    "#                 if first_index not in second_order_state_transition[second_index]:\n",
    "#                     second_order_state_transition[second_index][first_index] = {}\n",
    "                \n",
    "#                 if idx not in second_order_state_transition[second_index][first_index]:\n",
    "#                     second_order_state_transition[second_index][first_index][idx] = 1\n",
    "#                 else:\n",
    "#                     second_order_state_transition[second_index][first_index][idx] += 1\n",
    "                    \n",
    "\n",
    "            if counting_word <= 5:\n",
    "                print(counting_word,second_index,first_index,idx)\n",
    "            second_index = first_index    \n",
    "            first_index = idx\n",
    "                \n",
    "            counting_word += 1\n",
    "                \n",
    "\n",
    "    \n",
    "    return initial_state,first_order_state_transition,second_order_state_transition,counting_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state,first_order_state_transition,second_order_state_transition,counting_dict = compute_counting(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'anything': 1, 'among': 3, 'off': 2, 'the': 62, 'of': 23}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(list(initial_state.items())[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'anything': {'she': 1, 'selfclear': 1, 'they': 1, 'herself': 1},\n",
       " 'she': {'may': 1,\n",
       "  'wouldnt': 1,\n",
       "  'wont': 3,\n",
       "  'cant': 1,\n",
       "  'had': 2,\n",
       "  'look': 1,\n",
       "  'could': 1,\n",
       "  'does': 1,\n",
       "  'likes': 1,\n",
       "  'made': 1,\n",
       "  'makes': 1,\n",
       "  'didnt': 1,\n",
       "  'thinks': 2,\n",
       "  'wants': 1,\n",
       "  'done': 1,\n",
       "  'aint': 1,\n",
       "  'has': 1,\n",
       "  'say': 1,\n",
       "  'go': 1,\n",
       "  'was': 1,\n",
       "  'lived': 1,\n",
       "  'gets': 1,\n",
       "  'tended': 1,\n",
       "  'said': 1,\n",
       "  'is': 1,\n",
       "  'felt': 1,\n",
       "  'halted': 1,\n",
       "  'went': 1,\n",
       "  'should': 1,\n",
       "  'youre': 1,\n",
       "  'hadnt': 1,\n",
       "  'wanted': 1,\n",
       "  'seems': 1,\n",
       "  'never': 1,\n",
       "  'gave': 1,\n",
       "  'raised': 1,\n",
       "  'would': 1,\n",
       "  'swept': 1}}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(list(first_order_state_transition.items())[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'anything': {'she': {'may': 2}, 'they': {'wish': 1}},\n",
       " 'she': {'may': {'say': 1},\n",
       "  'wouldnt': {'have': 1},\n",
       "  'wont': {'come': 3, 'get': 2},\n",
       "  'had': {'the': 1, 'her': 1},\n",
       "  'look': {'like': 1},\n",
       "  'could': {'call': 2},\n",
       "  'does': {'it': 1},\n",
       "  'likes': {'it': 1},\n",
       "  'made': {'a': 2},\n",
       "  'makes': {'a': 1},\n",
       "  'didnt': {'know': 1},\n",
       "  'thinks': {'when': 2, 'if': 2},\n",
       "  'wants': {'our': 2},\n",
       "  'done': {'but': 1},\n",
       "  'aint': {'come': 1},\n",
       "  'has': {'her': 2},\n",
       "  'was': {'shut': 2},\n",
       "  'lived': {'her': 1},\n",
       "  'gets': {'her': 1},\n",
       "  'tended': {'both': 1},\n",
       "  'said': {'i': 1},\n",
       "  'felt': {'the': 1},\n",
       "  'halted': {'some': 1},\n",
       "  'should': {'shouldnt': 2},\n",
       "  'youre': {'so': 1},\n",
       "  'hadnt': {'found': 2},\n",
       "  'seems': {'to': 2},\n",
       "  'never': {'tended': 2},\n",
       "  'gave': {'judgment': 1},\n",
       "  'raised': {'her': 2},\n",
       "  'would': {'be': 1},\n",
       "  'swept': {'the': 2}}}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(list(second_order_state_transition.items())[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_prob(counting_dict,initial_state,first_order_state_transition,second_order_dict):\n",
    "    for i in second_order_dict:\n",
    "#         print(i)\n",
    "#         print(second_order_dict[i])\n",
    "        for j in second_order_dict[i]:\n",
    "            for k in second_order_dict[i][j]:\n",
    "                tmp_get = first_order_state_transition.get(i, {}).get(j,None)\n",
    "                if not tmp_get is None:\n",
    "                    second_order_dict[i][j][k] = second_order_dict[i][j][k]/tmp_get\n",
    "                else:\n",
    "                    second_order_dict[i][j][k] = 0\n",
    "#             print(i,j,k,tmp_get)\n",
    "#         print('------')\n",
    "        \n",
    "    for i in first_order_state_transition:\n",
    "#         print(i)\n",
    "#         print(first_order_state_transition[i])\n",
    "        for j in first_order_state_transition[i]:\n",
    "            tmp_get = counting_dict.get(i, None)\n",
    "            if not tmp_get is None:\n",
    "                first_order_state_transition[i][j] = first_order_state_transition[i][j]/tmp_get\n",
    "            else:\n",
    "                first_order_state_transition[i][j] = 0\n",
    "#             print(i,j,tmp_get)\n",
    "#         print('------')\n",
    "\n",
    "    all_word_length = len(initial_state)\n",
    "    for i in initial_state:\n",
    "#         print(i,initial_state[i],all_word_length)\n",
    "        initial_state[i] = initial_state[i]/all_word_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_prob(counting_dict,initial_state,first_order_state_transition,second_order_state_transition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'anything': 0.0036496350364963502,\n",
       " 'among': 0.010948905109489052,\n",
       " 'off': 0.0072992700729927005,\n",
       " 'the': 0.22627737226277372,\n",
       " 'of': 0.08394160583941605}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(list(initial_state.items())[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'anything': {'she': 0.14285714285714285,\n",
       "  'selfclear': 0.14285714285714285,\n",
       "  'they': 0.14285714285714285,\n",
       "  'herself': 0.14285714285714285},\n",
       " 'she': {'may': 0.023809523809523808,\n",
       "  'wouldnt': 0.023809523809523808,\n",
       "  'wont': 0.07142857142857142,\n",
       "  'cant': 0.023809523809523808,\n",
       "  'had': 0.047619047619047616,\n",
       "  'look': 0.023809523809523808,\n",
       "  'could': 0.023809523809523808,\n",
       "  'does': 0.023809523809523808,\n",
       "  'likes': 0.023809523809523808,\n",
       "  'made': 0.023809523809523808,\n",
       "  'makes': 0.023809523809523808,\n",
       "  'didnt': 0.023809523809523808,\n",
       "  'thinks': 0.047619047619047616,\n",
       "  'wants': 0.023809523809523808,\n",
       "  'done': 0.023809523809523808,\n",
       "  'aint': 0.023809523809523808,\n",
       "  'has': 0.023809523809523808,\n",
       "  'say': 0.023809523809523808,\n",
       "  'go': 0.023809523809523808,\n",
       "  'was': 0.023809523809523808,\n",
       "  'lived': 0.023809523809523808,\n",
       "  'gets': 0.023809523809523808,\n",
       "  'tended': 0.023809523809523808,\n",
       "  'said': 0.023809523809523808,\n",
       "  'is': 0.023809523809523808,\n",
       "  'felt': 0.023809523809523808,\n",
       "  'halted': 0.023809523809523808,\n",
       "  'went': 0.023809523809523808,\n",
       "  'should': 0.023809523809523808,\n",
       "  'youre': 0.023809523809523808,\n",
       "  'hadnt': 0.023809523809523808,\n",
       "  'wanted': 0.023809523809523808,\n",
       "  'seems': 0.023809523809523808,\n",
       "  'never': 0.023809523809523808,\n",
       "  'gave': 0.023809523809523808,\n",
       "  'raised': 0.023809523809523808,\n",
       "  'would': 0.023809523809523808,\n",
       "  'swept': 0.023809523809523808}}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(list(first_order_state_transition.items())[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'anything': {'she': {'may': 2.0}, 'they': {'wish': 1.0}},\n",
       " 'she': {'may': {'say': 1.0},\n",
       "  'wouldnt': {'have': 1.0},\n",
       "  'wont': {'come': 1.0, 'get': 0.6666666666666666},\n",
       "  'had': {'the': 0.5, 'her': 0.5},\n",
       "  'look': {'like': 1.0},\n",
       "  'could': {'call': 2.0},\n",
       "  'does': {'it': 1.0},\n",
       "  'likes': {'it': 1.0},\n",
       "  'made': {'a': 2.0},\n",
       "  'makes': {'a': 1.0},\n",
       "  'didnt': {'know': 1.0},\n",
       "  'thinks': {'when': 1.0, 'if': 1.0},\n",
       "  'wants': {'our': 2.0},\n",
       "  'done': {'but': 1.0},\n",
       "  'aint': {'come': 1.0},\n",
       "  'has': {'her': 2.0},\n",
       "  'was': {'shut': 2.0},\n",
       "  'lived': {'her': 1.0},\n",
       "  'gets': {'her': 1.0},\n",
       "  'tended': {'both': 1.0},\n",
       "  'said': {'i': 1.0},\n",
       "  'felt': {'the': 1.0},\n",
       "  'halted': {'some': 1.0},\n",
       "  'should': {'shouldnt': 2.0},\n",
       "  'youre': {'so': 1.0},\n",
       "  'hadnt': {'found': 2.0},\n",
       "  'seems': {'to': 2.0},\n",
       "  'never': {'tended': 2.0},\n",
       "  'gave': {'judgment': 1.0},\n",
       "  'raised': {'her': 2.0},\n",
       "  'would': {'be': 1.0},\n",
       "  'swept': {'the': 2.0}}}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ! something wrong! why prob is 2! ,(╯‵□′)╯︵┻━┻\n",
    "dict(list(second_order_state_transition.items())[0:2]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial_state_0,state_transition_0 = compute_counting([x for x,y in zip(X_train_int,y_train) if y ==0],initial_state_0,state_transition_0)\n",
    "# initial_state_0[:5],state_transition_0[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial_state_1,state_transition_1 = compute_counting([x for x,y in zip(X_train_int,y_train) if y ==1],initial_state_1,state_transition_1)\n",
    "# initial_state_1[:5],state_transition_1[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #compute prior\n",
    "# count_0 = sum(y == 0 for y in y_train)\n",
    "# count_1 = sum(y == 1 for y in y_train)\n",
    "# total_count = len(y_train)\n",
    "\n",
    "# p0 = count_0/total_count\n",
    "# p1 = count_1/total_count\n",
    "\n",
    "# log_p0 = np.log(p0)\n",
    "# log_p1 = np.log(p1)\n",
    "\n",
    "# p0,p1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_log_likelihood(tokens,initial_state,state_transition):\n",
    "#     log_prob = 0\n",
    "#     last_index = None\n",
    "#     for idx in tokens:\n",
    "#         if last_index is None:\n",
    "#             log_prob += initial_state[idx]\n",
    "#         else:\n",
    "#             log_prob +=state_transition[last_index,idx]\n",
    "#         last_index = idx\n",
    "    \n",
    "#     return log_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def predict(test_sentences,initial_state_list,state_transition_list,prior_list):\n",
    "    \n",
    "#     prob =[]\n",
    "#     for sentence in test_sentences:\n",
    "        \n",
    "#         prob_each_model = []\n",
    "#         model_number = len(initial_state_list)\n",
    "        \n",
    "#         for i in range(model_number):\n",
    "#             tmp_prob = compute_log_likelihood(sentence,initial_state_list[i],state_transition_list[i]) + prior_list[i]\n",
    "#             prob_each_model.append(tmp_prob)\n",
    "       \n",
    "#         pred = np.argmax(prob_each_model)\n",
    "#         prob.append(pred)\n",
    "        \n",
    "#     return np.asarray(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted_train = predict(X_train_int,[initial_state_0,initial_state_1],[state_transition_0,state_transition_1],[log_p0,log_p1]  )\n",
    "# np.mean(predicted_train ==np.asarray(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted_test = predict(X_test_int,[initial_state_0,initial_state_1],[state_transition_0,state_transition_1],[log_p0,log_p1])\n",
    "# np.mean(predicted_test ==np.asarray(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
